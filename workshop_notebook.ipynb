{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Воркшоп по AI для архитекторов: Практикa\n",
    "## Датасет\n",
    "\n",
    "Мы уже определились с тем, какую задачу мы будем решать. Нужно выбрать подходящий набор данных! Мы предподготовили для воркшопа четыре набора размеченных данных:\n",
    "\n",
    "* **green** - леса и парки\n",
    "* **water** - водные объекты\n",
    "* **residential** - жилые здания\n",
    "* **non-residential** - нежилые здания\n",
    "\n",
    "Каждый набор данных содержит две папки –– `train` (на данных из этой папки мы будем обучать нашу нейросеть) и `test` (на данных из этой папки мы будем проверять то, как работает наша нейросеть). \n",
    "\n",
    "В свою очередь, каждая из этих папок содержит две подпапки –– `tile` и `mask`. В папке `tile` находятся тайлы (кусочки) спутниковых снимков, а в папке `mask` для каждого такого снимка есть *маска* интересующих нас объектов с тайла.\n",
    "\n",
    "\n",
    "#### Упражненьице\n",
    "Нужно правильно прописать путь к папке `train`, чтобы запустить обучение на нужном датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/Users/slobanova/ipynbs/workshop/datasets/water/train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на картинки из датасета (попробуйте понажимать `Tab` в процессе написания пути):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.open('/Users/slobanova/ipynbs/workshop/datasets/water/train/tile/0.79166.41078.17.sat.tile.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open('/Users/slobanova/ipynbs/workshop/datasets/water/train/mask/0.79166.41078.17.mask.tile.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С такими парами изображений мы и будем работать. Будем пытаться находить на спутниковых снимках объекты, маски которых мы скормим нейросети.\n",
    "\n",
    "Чтобы в дальнейшем нам не приходилось каждый раз прописывать путь полностью (абсолютный путь), напишем функцию, которая будет возвращать нам путь к папке с текущим проектом. Тогда мы сможем использовать относительные, а не абсолютные пути:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def get_root():\n",
    "    return os.path.abspath('')\n",
    "\n",
    "# Получим путь к папке проекта:\n",
    "root = get_root()\n",
    "\n",
    "# Выведем путь\n",
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А тут давайте укажем название датасета, с которым хотим работать. Это понадобится нам в дальнейшем как составная часть относительного пути:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'water'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс датасета\n",
    "\n",
    "В библиотеке `torch`, которой мы собираемся пользоваться, для работы с данными, необходимо их описать особым образом. Этот способ описания позволяет привести данные к единому виду, а библиотеке обращаться к разным датасетам одного типа одинаково."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь мы импортируем нужные для работы кода библиотеки\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# Здесь мы описываем атрибуты и способы работы с нашим датасетом\n",
    "class MaskDataset(object):\n",
    "    # Инициализация датасета\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        \n",
    "        # Загрузка масок из папки\n",
    "        masks = list(sorted(os.listdir(os.path.join(root, \"mask\"))))\n",
    "        self.masks = []\n",
    "        self.imgs = []\n",
    "        \n",
    "        # Для каждой маски мы находим соответствующий спутниковый снимок\n",
    "        for mask_file in masks:\n",
    "            img_mask_path = os.path.join(root, 'mask', mask_file)\n",
    "            img_file = mask_file.replace('.mask.', '.sat.').replace('.png', '.jpg')\n",
    "            img_mask = Image.open(img_mask_path).quantize(colors=256, method=2)\n",
    "            img_mask = np.array(img_mask)\n",
    "            if np.min(img_mask) == np.max(img_mask):\n",
    "                continue\n",
    "\n",
    "            self.masks.append(mask_file)\n",
    "            self.imgs.append(img_file)\n",
    "\n",
    "    # Обработка значений минимума и максимума для ббоксов (нужна для пограничных случаев)\n",
    "    @staticmethod\n",
    "    def _normalize_min_max(min_, max_):\n",
    "        if min_ == max_:\n",
    "            if max_ == 255:\n",
    "                min_ -= 1\n",
    "            else:\n",
    "                max_ += 1\n",
    "        elif min_ > max_:\n",
    "            min_, max_ = max_, min_\n",
    "\n",
    "        return min_, max_\n",
    "\n",
    "    # Этот метод описывает получение объекта (пара \"снимок+маска\") и его свойств\n",
    "    def __getitem__(self, idx):\n",
    "        # Загружаем снимки и маски\n",
    "        img_path = os.path.join(self.root, \"tile\", self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, \"mask\", self.masks[idx])\n",
    "\n",
    "        img_mask = Image.open(mask_path).quantize(colors=256, method=2)\n",
    "        img_mask = np.array(img_mask)\n",
    "\n",
    "        # Уникальный цвет на маске соответствует уникальному типу объекта\n",
    "        obj_ids = np.unique(img_mask)\n",
    "        # Первый цвет в списке - цвет фона, так что мы убираем его из списка цветов объектов\n",
    "        obj_ids = obj_ids[1:]\n",
    "\n",
    "        # Собираем бинарную маску, в которой для каждого пикселя будет говориться, есть ли на нем искомый объект\n",
    "        masks = img_mask == obj_ids[:, None, None]\n",
    "        masks = np.bitwise_not(masks)\n",
    "\n",
    "        # Получаем ббоксы для каждого снимка\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        try:\n",
    "            for i in range(num_objs):\n",
    "                pos = np.where(masks[i])\n",
    "                xmin = np.min(pos[1])\n",
    "                xmax = np.max(pos[1])\n",
    "                ymin = np.min(pos[0])\n",
    "                ymax = np.max(pos[0])\n",
    "\n",
    "                xmin, xmax = self._normalize_min_max(xmin, xmax)\n",
    "                ymin, ymax = self._normalize_min_max(ymin, ymax)\n",
    "\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        except IndexError as e:\n",
    "            print(e)\n",
    "            print(img_path)\n",
    "            print(mask_path)\n",
    "            raise\n",
    "\n",
    "        # Конвертируем полученные ббоксы в тензор\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # У нас только один класс - вешаем ярлыки-единички на все объекты на снимке\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "\n",
    "        if boxes.size()[0] > 0:\n",
    "            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        else:\n",
    "            area = torch.as_tensor(0)\n",
    "        \n",
    "        # Здесь описываем атрибуты объекта в нашем датасете\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"area\"] = area\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "    \n",
    "        # Применяем преобразования к снимкам\n",
    "        transforms = self.get_transform()\n",
    "        img_tensor = transforms(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "        return img_tensor, target\n",
    "\n",
    "    # С помощью этого метода мы сможем получать количество объектов в датасете\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    # С помощью этого метода мы получаем список трансформаций - преобразований исходных элементов датасета\n",
    "    def get_transform(self):\n",
    "        transforms = list()\n",
    "        \n",
    "        # Наше единственное преобразование - перевод изображения в формат тензора (библиотека pytorch работает только с тензорами)\n",
    "        transforms.append(T.ToTensor())\n",
    "\n",
    "        return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем загрузить данные из папки `train` в описанную структуру:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь мы определим размер валидационной выборки\n",
    "val_subset_number = 10\n",
    "\n",
    "# Загружаем данные из папки\n",
    "whole_dataset = MaskDataset(os.path.join(root, 'datasets', DATASET, 'train'))\n",
    "\n",
    "# Создадим список перемешанных номеров элементов датасета\n",
    "indices = torch.randperm(len(whole_dataset)).tolist()\n",
    "\n",
    "# Переопределим датасеты - теперь данные в них перемешаны\n",
    "train_dataset = torch.utils.data.Subset(whole_dataset, indices[:-val_subset_number])\n",
    "val_dataset = torch.utils.data.Subset(whole_dataset, indices[-val_subset_number:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `torch` для того, чтобы получать батчи данных из датасета, используется объект типа [DataLoader](https://pytorch.org/docs/stable/_modules/torch/utils/data/dataloader.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Создадим DataLoader для тренировочного датасета:\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, # Здесь мы определяем датасет, для которого создается лодер\n",
    "    batch_size=2, # Определим количество элементов в батче\n",
    "    shuffle=True, # Будем перемешивать данные внутри датасета каждую эпоху\n",
    "    collate_fn=utils.collate_fn # Вспомогательная функция, приводит данные в батче к определенному виду\n",
    ")\n",
    "\n",
    "# Создадим DataLoader для валидационного датасета:\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=utils.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ура! Мы разобрались с датасетом!\n",
    "\n",
    "## Выбор модели и загрузка весов\n",
    "\n",
    "Теперь необходимо определиться с архитектурой сети, которую мы собираемся использовать в качестве backbone. В `torch` реализовано много [моделей](https://pytorch.org/docs/stable/torchvision/models.html), мы же будем работать со следующими:\n",
    "* [ResNet](https://arxiv.org/abs/1512.03385)\n",
    "* [MobileNetV2](https://arxiv.org/abs/1801.04381)\n",
    "\n",
    "Вы должны определиться с тем, какую архитектуру вы будете использовать в этом проекте –– укажите `resnet` или `mobilenet` в поле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK = 'resnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая функция возвращает нам выбранную модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(network='resnet', num_classes = 2):\n",
    "    \n",
    "    import torchvision\n",
    "    from torchvision.models.detection import FasterRCNN, MaskRCNN\n",
    "    from torchvision.models.detection.rpn import AnchorGenerator\n",
    "    from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "    if network == 'resnet':\n",
    "        \n",
    "        # Загружаем \"чистую\" модель\n",
    "        model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=False)\n",
    "\n",
    "        # В качестве предиктора ббоксов выберем FastRCNNPredictor, меняем количество выходных нейронов на количество классов = 2\n",
    "        in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    \n",
    "    if network == 'mobilenet':\n",
    "        \n",
    "        # Загружаем \"чистую\" модель\n",
    "        backbone = torchvision.models.mobilenet_v2(pretrained=False).features\n",
    "        backbone.out_channels = 1280\n",
    "    \n",
    "        # Инициализируем генератор окон разных размеров\n",
    "        anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
    "                                           aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "\n",
    "        # Здесь мы инициализируем \"голову\" сети (предсказатель предполагаемых объектов)\n",
    "        roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0], # Ищем единственный объект\n",
    "                                                        output_size=7, # Размер выходного RoI\n",
    "                                                        sampling_ratio=2) # Количество опорных точек\n",
    "\n",
    "\n",
    "        # Собираем MaskRCNN модель из частей\n",
    "        model = MaskRCNN(backbone,\n",
    "                         num_classes=2,\n",
    "                         rpn_anchor_generator=anchor_generator,\n",
    "                         box_roi_pool=roi_pooler)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    else:\n",
    "        print('Неправильная модель, попробуй \"resnet\" и \"mobilenet\"')\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим модель с помощью функции `get_model()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(NETWORK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательная функция для формирования названия файла с весами (нужна будет для сохранения и загрузки весов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_filepath(epoch, dataset, network, is_train=False):\n",
    "\n",
    "    file_segments = []\n",
    "\n",
    "    if is_train:\n",
    "        file_segments.append('train')\n",
    "\n",
    "    if epoch is not None:\n",
    "        file_segments.append('ep{}'.format(epoch))\n",
    "\n",
    "    file_segments.append(dataset)\n",
    "    file_segments.append(network)\n",
    "\n",
    "    root = get_root()\n",
    "    file_name = '_'.join(file_segments) + '.pt'\n",
    "    return os.path.join(root, 'weights', file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из особенностей библиотеки PyTorch - возможность работы с GPU. Это позволит нам быстрее работать с моделью: тренировать ее и получать предсказания. Чтобы узнать, можем ли мы использовать GPU, запустим ячейку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "device.type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы увидели `'cpu'` - чтож, обучать модель вам будет дольше по времени. Остальные могут выдохнуть. Да-да, это несправделивый мир машинного обучения, в котором вычислительные мощности решают!\n",
    "\n",
    "#### Загрузка весов\n",
    "\n",
    "В нашем воркшопе мы используем предподготовленные веса. Это значит, что мы будем инициализировать веса в нашей модели не случайным образом, а загрузим \"сейв\", который кто-то когда-то сделал для этой же архитектуры.\n",
    "\n",
    "Все веса расположены в папке `weights`. Для каждого набора данных мы обучали сети обеих архитектур на протяжении 35-45 эпох. Результаты работы после такого обучения не идеальны, но уже гораздо лучше, чем после случайной инициализации. В этом модуле мы загрузим веса в модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = DATASET + '_' + NETWORK + '_' + 'initial_weights.pt'\n",
    "\n",
    "WEIGHTS = os.path.join(root, 'weights', weights_file)\n",
    "\n",
    "if not os.path.isfile(WEIGHTS):\n",
    "    print('Нет таких весов!')\n",
    "\n",
    "# Загружаем веса\n",
    "model.load_state_dict(torch.load(WEIGHTS))\n",
    "# model.load_state_dict(torch.load(WEIGHTS, map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "# Загружаем модель в память устройства\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизатор и гиперпараметры\n",
    "\n",
    "_<..Вставьте еще одну лекцию и сто презентаций..>_\n",
    "\n",
    "Оптимизатор - движущая сила всего процесса обучения. Именно он занимается обновлением весов модели, поэтому от того, как мы его зададим, зависит то, насколько быстро наша модель станет давать приемлемые предсказания, станет ли она их давать вообще и в принципе весь результат.\n",
    "\n",
    "Вот [тут](https://pytorch.org/docs/stable/optim.html) можно посмотреть список всех методов оптимизации, зашитых в библиотеку PyTorch. Вы можете использовать любой по желанию, если разберетесь. А если нет - в ячейке ниже уже описана парочка таких методов (я надеюсь, что к этому моменту мы уже рассказали вам про них):\n",
    "* [SGD](https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html)\n",
    "* [Adam](https://pytorch.org/docs/stable/_modules/torch/optim/adam.html)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем список всех весов в модели\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "\n",
    "# Выбираем оптимизатор и указываем его параметры\n",
    "\n",
    "# Градиентный спуск\n",
    "optimizer = torch.optim.SGD(params,\n",
    "                            lr=0.005, # Коэффициент скорости обучения, должен быть не слишком большим и не слишком маленьким\n",
    "                            momentum=0.9, # Коэффициент \"ускорения\"\n",
    "                            weight_decay=0.0005 # Коэффициент устойчивости нестабильных весов\n",
    "                           )\n",
    "\n",
    "# Adam\n",
    "optimizer = torch.optim.Adam(params,\n",
    "                             lr=0.001,\n",
    "                             weight_decay=0.0005\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "\n",
    "Ну что, перейдем к самой ответственной части? Нужно собрать все вместе: датасет, модель, оптимизатор.. И обучать модель. Как обычно, параметры `NUM_EPOCHS` и `EPOCH_SAVING_RATE` останутся на ваше усмотрение, но мы настоятельно рекомендуем сохраняться не реже раза в 5 эпох, а количество эпох для обучения оценивать трезво - модель должна успеть доучиться до завтра, но при этом не __пере__обучиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем функцию для динамического обновления коэффициента скорости обучения\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, # будем обновлять коэффициент в нашем оптимизаторе\n",
    "                                               step_size=3, # каждые N эпох коэффициент будет обновляться\n",
    "                                               gamma=0.1 # как будет изменяться коэффициент (new_lr = lr * gamma)\n",
    "                                              )\n",
    "\n",
    "# Количество эпох\n",
    "NUM_EPOCHS = 2\n",
    "# Будем сохранять веса каждые N эпох:\n",
    "EPOCH_SAVING_RATE = 5\n",
    "\n",
    "import time\n",
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "print('Начинаем обучать модель: {}'.format(time.asctime()))\n",
    "print('Устройство: {}'.format(device))\n",
    "print('Датасет: {}'.format(DATASET))\n",
    "print('Модель: {}'.format(NETWORK))\n",
    "print('Эпохи: {}'.format(NUM_EPOCHS))\n",
    "\n",
    "print('Загруженные веса: {}'.format(WEIGHTS))\n",
    "\n",
    "print('--- -- -- -- -- -- ---')\n",
    "\n",
    "# Список для хранения времени обучения за эпоху\n",
    "learning_ts_list = list()\n",
    "\n",
    "loss_acc_list = []\n",
    "val_accuracy_list = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_learning_ts = time.time()\n",
    "\n",
    "    try:\n",
    "        # Тренируем одну эпоху, выводим информацию каждые 10 батчей\n",
    "        loss_acc_dict = train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=10)\n",
    "\n",
    "        # Обновим коэффициент скорости обучения оптимизатора:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # Оценка на валидационном датасете\n",
    "        val_accuracies = evaluate(model, val_loader, device=device)\n",
    "        \n",
    "        mean_acc = float(np.mean(val_accuracies))\n",
    "        \n",
    "        print('Эпоха {} окончена, средняя accuracy на обучении {}%'.format(epoch, mean_acc * 100))\n",
    "        \n",
    "        #  Сохраним для истории loss и accuracy\n",
    "        with torch.no_grad():\n",
    "            loss_acc_list.append(loss_acc_dict)\n",
    "            val_accuracy_list.append(mean_acc)\n",
    "            \n",
    "        # Сохраняем веса в отдельный файл каждые EPOCH_SAVING_RATE эпох\n",
    "        if epoch >= EPOCH_SAVING_RATE and epoch % EPOCH_SAVING_RATE == 0:\n",
    "            train_weights_file_path = get_weights_filepath(epoch=epoch, dataset=DATASET, network=NETWORK, is_train=True)\n",
    "            torch.save(model.state_dict(), train_weights_file_path)\n",
    "\n",
    "    # Если произойдет какая-либо ошибка, мы хотим ее вывести и сохранить текущие веса\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(e)\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "        # Сохраняем текущие веса\n",
    "        train_weights_file_path = get_weights_filepath(epoch=epoch, dataset=DATASET, network=NETWORK, is_train=True)\n",
    "        torch.save(model.state_dict(), train_weights_file_path)\n",
    "\n",
    "    # Записываем, сколько времени мы потратили на эту эпоху (интересно и познавательно)\n",
    "    epoch_learning_ts = time.time() - epoch_learning_ts\n",
    "    learning_ts_list.append(epoch_learning_ts)\n",
    "    avg_learn_time = np.mean(learning_ts_list)\n",
    "\n",
    "    print('Время обучения: {} сек'.format(int(epoch_learning_ts)))\n",
    "    print('Среднее время обучения: {} сек'.format(int(avg_learn_time)))\n",
    "\n",
    "# Сохраняем конечные веса модели после обучения\n",
    "weights_file_path = get_weights_filepath(epoch=None, dataset=DATASET, network=NETWORK, is_train=False)\n",
    "torch.save(model.state_dict(), weights_file_path)\n",
    "\n",
    "print(\"Вот и всё!\")\n",
    "\n",
    "# Преобразуем словаль со статистикой по обучению в отдельные переменные\n",
    "tr_accuracy_list = [np.mean(x['tr_accuracy_list']) for x in loss_acc_list]\n",
    "loss_aggregate = [np.mean(x['loss_aggregate']) for x in loss_acc_list]\n",
    "loss_classifier = [np.mean(x['loss_classifier']) for x in loss_acc_list]\n",
    "loss_box_reg = [np.mean(x['loss_box_reg']) for x in loss_acc_list]\n",
    "loss_mask = [np.mean(x['loss_mask']) for x in loss_acc_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построим график loss и метрики качества\n",
    "\n",
    "Чтобы диагностировать проблемы при обучении, полезно иногда смотреть на то, как изменяется со временем loss и accuracy на тренировочном и валидационном датасетах. Если грубо говорить, _loss_ должна убывать со временем, а _accuracy_ расти.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15, 20))\n",
    "\n",
    "\n",
    "# Нарисуем первый график, он будет показывать, как изменялись loss'ы по эпохам на трейне и на валидации\n",
    "\n",
    "ax[0].plot(list(range(len(loss_classifier))), loss_classifier, label='Classifier loss', c='c')\n",
    "\n",
    "ax[0].plot(list(range(len(loss_box_reg))), loss_box_reg, label='Bbox regression loss', c='m')\n",
    "\n",
    "ax[0].plot(list(range(len(loss_mask))), loss_mask, label='Mask loss', c='y')\n",
    "\n",
    "ax[0].plot(list(range(len(loss_aggregate))), loss_aggregate, label='Aggregated loss', linewidth=3, c='0.5')\n",
    "\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Losses')\n",
    "ax[0].legend(loc='upper right')\n",
    "\n",
    "\n",
    "# Нарисуем второй график, он будет показывать, как изменялись аккураси и совокупный loss по эпохам на трейне и на валидации\n",
    "\n",
    "ax[1].plot(list(range(len(tr_accuracy_list))), tr_accuracy_list, label='Train accuracy', linestyle='--', c='y')\n",
    "ax[1].plot(list(range(len(val_accuracy_list))), val_accuracy_list, label='Validation accuracy', c='y')\n",
    "\n",
    "ax[1].plot(list(range(len(loss_aggregate))), loss_aggregate, label='Training aggregated loss', linewidth=3, linestyle='--', c='0.5')\n",
    "\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy & aggregated loss')\n",
    "ax[1].legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим, что же у нас вышло\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну что, наверное хочется посмотреть, как работает наш алгоритм? Это можно сделать, посмотрев на предсказание, полученное моделью `pred = model(img)`, однако его не очень приятно читать и довольно сложно соотнести с реальным изображением. Чтобы было проще узнать, что и где нашла наша сеть, используем пару новых функций и сохраним изображения в папку `result`.\n",
    "\n",
    "Для начала разберемся, с каким датасетом мы будем работать, и куда сохраним результаты. Если предыдущие части кода вы запускали относительно давно, то компьютеру нужно будет освежить память и задать нужные нам переменные заново."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Это секция с закоментированными строками может пригодиться, если в памяти компьютера не осталось переменных с обучения\n",
    "\n",
    "# weights_file_path = '/Users/slobanova/ipynbs/workshop/weights/water_resnet_initial_weights.pt'\n",
    "\n",
    "# model = get_model('mobilenet')\n",
    "\n",
    "# model.load_state_dict(torch.load(weights_file_path, map_location=torch.device('cpu')))\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "# DATASET = 'water'\n",
    "\n",
    "\n",
    "# Указываем путь к папке со снимками для проверки\n",
    "dataset_path = os.path.join(root, 'datasets', DATASET, 'train')\n",
    "\n",
    "# Указываем путь для сохранения итоговых изображений\n",
    "result_path = os.path.join(root, 'result')\n",
    "\n",
    "# Задаем названия лейблов для ббоксов\n",
    "OBJECT_LABELS = [\n",
    "    '__background__', DATASET\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем функцию, которая будет получать предсказание от модели и в зависимости от вероятности наличия объекта (вероятность больше или меньше порогового значения `threshold`) будет передавать объекты в функцию для рисования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для получения списка преобразований\n",
    "def get_transform(train):\n",
    "    transforms = [\n",
    "        T.ToTensor(),\n",
    "    ]\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "# Функция для получения предсказания для спутникого снимка\n",
    "def get_prediction(img_path, threshold):\n",
    "    \n",
    "    from matplotlib import pyplot as plt\n",
    "    from PIL import Image\n",
    "    from torchvision import transforms as T\n",
    "    \n",
    "    # Переводим модель в режим оценки\n",
    "    model.eval()\n",
    "    \n",
    "    img = Image.open(img_path)  # Открываем картинку\n",
    "    transform = T.Compose([T.ToTensor()])  \n",
    "    img = transform(img) # Применяем к ней трансформации\n",
    "    \n",
    "    pred = model([img])  # Получаем предсказание модели по снимку\n",
    "    \n",
    "    pred_class = [OBJECT_LABELS[i] for i in list(pred[0]['labels'].cpu().numpy())]  # Получаем классы распознанных объектов - лейблы\n",
    "    pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().cpu().numpy())]  # Получаем ббоксы объектов\n",
    "    pred_score = list(pred[0]['scores'].detach().cpu().numpy()) # Получаем вероятности для объектов\n",
    "    pred_masks = list(pred[0]['masks'].detach().cpu().numpy()) # Маски объектов\n",
    "    \n",
    "    print(os.path.basename(img_path))\n",
    "    \n",
    "    # Здесь мы выбираем объекты, вероятность которых > threshold\n",
    "    \n",
    "    pred_selected = [pred_score.index(x) for x in pred_score]\n",
    "    \n",
    "    if len(pred_selected) == 0:\n",
    "        return [], [], [], []\n",
    "\n",
    "    pred_filtered_values = [x for x in pred_score if x > threshold]\n",
    "    \n",
    "    if len(pred_filtered_values) == 0:\n",
    "        return [], [], [], []\n",
    "\n",
    "    print(\"Вероятности для всех найденных объектов: {}.\".format(pred_score))\n",
    "\n",
    "    pred_selected = [pred_score.index(x) for x in pred_score if x > threshold]\n",
    "    pred_boxes = [pred_boxes[idx] for idx in pred_selected]\n",
    "    pred_class = [pred_class[idx] for idx in pred_selected]\n",
    "    pred_score = [pred_score[idx] for idx in pred_selected]\n",
    "    pred_masks = [pred_masks[idx] for idx in pred_selected]\n",
    "    \n",
    "    return pred_boxes, pred_class, pred_score, pred_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для отрисовки найденных объектов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Функция рисования результатов обработки, сохраняет снимок с нанесенными ббоксами и отдельно предсказанную маску\n",
    "def object_detection_api(img_path, threshold=0.15, rect_th=1, text_size=0.4, text_th=3):\n",
    "    boxes, pred_cls, scores, masks = get_prediction(img_path, threshold)  # Получим данные о найденных объектах на снимке\n",
    "    img = cv2.imread(img_path)  # Читаем изображение\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Конвертируем цвета (особенность работы с cv2)\n",
    "\n",
    "    # Рисуем ббокс\n",
    "    for i in range(len(boxes)):\n",
    "        cv2.rectangle( # Добавляем прямоугольник ббокса на картинку\n",
    "            img,\n",
    "            boxes[i][0],\n",
    "            boxes[i][1],\n",
    "            color=(0, 255, 0),\n",
    "            thickness=rect_th\n",
    "        )\n",
    "        cv2.putText( # Добавляем подпись к прямоугольнику (вероятность)\n",
    "            img,\n",
    "            str(scores[i]),\n",
    "            boxes[i][0],\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            text_size,\n",
    "            color=(0, 255, 0),\n",
    "            thickness=1\n",
    "        )\n",
    "\n",
    "    height, width, _ = img.shape\n",
    "    \n",
    "    # Сделаем пустой холст для рисования маски\n",
    "    heatmap_mask = np.zeros((256,256), dtype=np.uint8)\n",
    "    \n",
    "    # Накладываем единичные маски друг на друга\n",
    "    for i in range(len(masks)):\n",
    "        the_mask = masks[i][0]\n",
    "        heatmap_mask = np.uint8(255 * the_mask) + heatmap_mask\n",
    "\n",
    "    # Сохраняем изображение с ббоксами\n",
    "    plt.imshow(img)\n",
    "    saving_file = os.path.join(result_path, os.path.basename(img_path).replace('.sat.', '.bbox.'))\n",
    "    plt.savefig(saving_file)\n",
    "\n",
    "    # Сохраняем изображение маски\n",
    "    plt.imshow(heatmap_mask)\n",
    "    saving_file = os.path.join(result_path, os.path.basename(img_path).replace('.sat.', '.heat.'))\n",
    "    plt.savefig(saving_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем запустить каскад функций (параметр `threshold` можно и нужно менять):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = os.scandir(os.path.join(dataset_path, 'tile'))\n",
    "\n",
    "for i, item in enumerate(data):\n",
    "    object_detection_api(item.path, threshold = 0.5)\n",
    "    \n",
    "    # Будем смотреть первые 20 снимков\n",
    "    if i == 19:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно посмотреть на эти картинки в папке. Погнали!\n",
    "\n",
    "## Запуск на новых данных\n",
    "\n",
    "Если вы дошли до этого этапа, то с большой вероятностью вы смогли выполнить предыдущий шаг. Сейчас мы попробуем получить результаты алгоритма на снимках Санкт-Петербурга. Эти снимки хранятся в папке `test`. Мы специально не трогали этот набор данных до последнего: сейчас мы будем смотреть, как же в реальности работает наш алгоритм на данных, которых он раньше не видел.\n",
    "\n",
    "#### Упражненьице\n",
    "\n",
    "* Создайте новую папку для сохранения результатов. Например, `spb_result`\n",
    "* Получите обработанные сетью картинки и сохраните их в эту папку\n",
    "\n",
    "_Не стесняйтесь спрашивать, если что-то не понятно!_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
